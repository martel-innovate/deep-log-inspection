version: '3.3'
services:

    zookeeper:
        image: zookeeper:3.3
        networks:
            - backend
        deploy:
            labels:
                - "traefik.enable=false"
            mode: replicated
            replicas: 1
            placement:
                constraints:
                  - node.role == manager
            restart_policy:
                condition: on-failure

    kafka:
        image: monasca/kafka:0.9.0.1-2.11
        environment:
            ZOOKEEPER_CONNECTION_STRING: "zookeeper:2181"
            KAFKA_HOSTNAME_FROM_IP: "false"
            KAFKA_ADVERTISED_HOST_NAME: "kafka"
            KAFKA_AUTO_CREATE_TOPICS: "false"
            KAFKA_DELETE_TOPIC_ENABLE: "true"
            KAFKA_CREATE_TOPICS: "\
                monasca-log:64:1,\
                logstash-log:64:1,\
                kafka-health:64:1"
            SERVER_LOG_LEVEL: "DEBUG"
        networks:
            - backend
        depends_on:
            - zookeeper
        deploy:
            labels:
                - "traefik.enable=false"
            mode: replicated
            replicas: 1
            placement:
                constraints:
                  - node.role == manager
            restart_policy:
                condition: on-failure

    monasca-log-api:
        image: martel/monasca-log-api
        environment:
            CONFIG_TEMPLATE: "true"
            LOG_LEVEL_ROOT: "INFO"
            LOG_LEVEL_CONSOLE: "INFO"
            MONASCA_CONTAINER_LOG_API_PORT: 8090
            KAFKA_URI: "kafka:9092"
            KAFKA_WAIT_FOR_TOPICS: "monasca-log,logstash-log"
            KAFKA_WAIT_RETRIES: 24
            KAFKA_WAIT_DELAY: 5
            KEYSTONE_IDENTITY_URI: "http://keystone:35357"
            KEYSTONE_AUTH_URI: "http://keystone:5000"
            KEYSTONE_ADMIN_USER: "admin"
            KEYSTONE_ADMIN_PASSWORD: "secretadmin"
            KEYSTONE_ADMIN_TENANT: "admin"
            KEYSTONE_ADMIN_DOMAIN: "default"
            AUTHORIZED_ROLES: "monasca-log-api"
            AGENT_AUTHORIZED_ROLES: "monasca-log-agent"
            GUNICORN_WORKERS: 9
            GUNICORN_WORKER_CLASS: "gevent"
            GUNICORN_WORKER_CONNECTIONS: 2000
            GUNICORN_BACKLOG: 1000
            GUNICORN_TIMEOUT: 1000
            MAX_MESSAGE_SIZE: 1048576
            LOG_PUBLISHER_TOPIC: "monasca-log"
            KAFKA_HEALTH_TOPIC: "kafka-health"
        networks:
            - backend
        depends_on:
            - kafka
        deploy:
            labels:
                - "traefik.backend=monasca-log-api"
                - "traefik.backend.loadbalancer.method=wrr"
                - "traefik.backend.loadbalancer.swarm=false"
                - "traefik.docker.network=backend"
                - "traefik.enable=true"
                - "traefik.frontend.entryPoints=https"
                - "traefik.frontend.passHostHeader=false"
                - "traefik.frontend.rule=Host:${DOMAIN:-example.com};Method:POST,HEAD,GET;PathPrefix:/v3.0,/healthcheck"
                - "traefik.port=8090"
            mode: replicated
            replicas: 1
            placement:
                constraints:
                  - node.role == manager
            restart_policy:
                condition: on-failure

    log-transformer:
        image: martel/log-transformer
        environment:
            LS_JAVA_OPTS: "-Xmx256m -Xms256m"
        networks:
            - backend
        depends_on:
          - kafka
        deploy:
            labels:
                - "traefik.enable=false"
            mode: replicated
            replicas: 1
            placement:
                constraints:
                  - node.role == manager
            restart_policy:
                condition: on-failure
        configs:
            - source: transformer_config
              target: /usr/share/logstash/config/logstash.yml
            - source: transformer_pipeline
              target: /usr/share/logstash/pipeline/logstash.conf

    log-persister:
        image: martel/log-persister
        environment:
            LS_JAVA_OPTS: "-Xmx256m -Xms256m"
        networks:
            - backend
        depends_on:
            - kafka
            - elasticsearch
        deploy:
            labels:
                - "traefik.enable=false"
            mode: replicated
            replicas: 1
            placement:
                constraints:
                    - node.role == manager
            restart_policy:
                condition: on-failure
        configs:
            - source: persister_config
              target: /usr/share/logstash/config/logstash.yml
            - source: persister_pipeline
              target: /usr/share/logstash/pipeline/logstash.conf

    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:5.4.0
        environment:
            cluster.name: "deeplog"
            bootstrap.memory_lock: "true"
            discovery.zen.minimum_master_nodes: 2
            discovery.zen.ping.unicast.hosts: "elasticsearch"
            discovery.type: "zen"
            gateway.expected_nodes: 3
            gateway.recover_after_nodes: 2
            xpack.security.enabled: "false"
            xpack.monitoring.enabled: "false"
            xpack.ml.enabled: "false"
            xpack.graph.enabled: "false"
            xpack.watcher.enabled: "false"
            ES_JAVA_OPTS: "-Xms512m -Xmx512m"
        volumes:
            - esdata:/usr/share/elasticsearch/data
            - eslogs:/usr/share/elasticsearch/logs
        networks:
            - backend
        deploy:
            labels:
                - "traefik.backend=elasticsearch"
                - "traefik.backend.circuitbreaker.expression=NetworkErrorRatio() > 0.5"
                - "traefik.backend.loadbalancer.method=wrr"
                - "traefik.backend.loadbalancer.swarm=false"
                - "traefik.backend.loadbalancer.sticky=false"
                - "traefik.docker.network=backend"
                - "traefik.enable=true"
                - "traefik.frontend.entryPoints=https"
                - "traefik.frontend.passHostHeader=false"
                - "traefik.frontend.rule=Host:elastic.${DOMAIN:-example.com}"
                - "traefik.port=9200"
            endpoint_mode: dnsrr
            mode: global
            resources:
                limits:
                    memory: 1g
            restart_policy:
                condition: on-failure
            update_config:
                parallelism: 1
                delay: 1m30s

    kibana:
        image: docker.elastic.co/kibana/kibana:5.4.0
        environment:
            SERVER_NAME: "kibana"
            SERVER_HOST: "0.0.0.0"
            ELASTICSEARCH_URL: "http://elasticsearch:9200"
            XPACK_SECURITY_ENABLED: "false"
            XPACK_MONITORING_ENABLED: "false"
            XPACK_ML_ENABLED: "false"
            XPACK_GRAPH_ENABLED: "false"
            XPACK_REPORTING_ENABLED: "false"
        networks:
            - backend
        depends_on:
            - elasticsearch
        deploy:
            labels:
                - "traefik.backend=kibana"
                - "traefik.backend.circuitbreaker.expression=NetworkErrorRatio() > 0.5"
                - "traefik.backend.loadbalancer.method=wrr"
                - "traefik.backend.loadbalancer.swarm=false"
                - "traefik.backend.loadbalancer.sticky=true"
                - "traefik.docker.network=backend"
                - "traefik.enable=true"
                - "traefik.frontend.entryPoints=https"
                - "traefik.frontend.passHostHeader=false"
                - "traefik.frontend.rule=Host:kibana.${DOMAIN:-example.com}"
                - "traefik.port=5601"
            mode: global
            restart_policy:
                condition: on-failure

    traefik:
        image: traefik
        command:
            - --web
            - --docker
            - --docker.domain=${DOMAIN:-example.com}
            - --docker.endpoint=unix:///var/run/docker.sock
            - --docker.swarmmode
            - --docker.watch
            - --debug=true
            - --logLevel=ERROR
        networks:
            - backend
        ports:
            - "80:80"
            - "443:443"
            - "8080:8080"
        volumes:
            - /var/run/docker.sock:/var/run/docker.sock
            - /etc/letsencrypt:/etc/letsencrypt
        deploy:
            labels:
                - "traefik.enable=false"
            mode: replicated
            placement:
                constraints:
                    - node.role == manager
            replicas: 1
            restart_policy:
                condition: on-failure
        configs:
            - source: traefik_config
              target: /etc/traefik/traefik.toml


volumes:
    esdata:
        external: true
    eslogs:
        external: true

networks:
    backend:
        external: true

configs:
    transformer_config:
        file: ./log-transformer/config/logstash.yml
    transformer_pipeline:
        file: ./log-transformer/pipeline/logstash.conf
    persister_config:
        file: ./log-persister/config/logstash.yml
    persister_pipeline:
        file: ./log-persister/pipeline/logstash.conf
    traefik_config:
        file: ./traefik/traefik.toml
